{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ldj7672/LLM-Tutorials/blob/main/examples/OpenAI_API_call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# **OpenAI API Call**\n","\n","**OpenAI**의 **Chat API**를 호출해 보는 간단한 실습 코드입니다."],"metadata":{"id":"IGSKG41yelP_"}},{"cell_type":"markdown","source":["## **1. 환경 세팅**\n","- OpenAI 라이브러리 설치\n","- API Key 입력"],"metadata":{"id":"cml80vUosW3m"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Lg9EMEGXsK09","executionInfo":{"status":"ok","timestamp":1737545179673,"user_tz":-540,"elapsed":5716,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}}},"outputs":[],"source":["!pip -q install openai"]},{"cell_type":"code","source":["from openai import OpenAI\n","import os\n","from getpass import getpass\n","\n","# Colab에 API 키를 안전하게 입력받기\n","api_key = getpass(\"OpenAI API 키를 입력하세요: \")\n","\n","# API 키를 환경 변수에 저장\n","os.environ['OPENAI_API_KEY'] = api_key"],"metadata":{"id":"QmIPe8Kvsjav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737545192014,"user_tz":-540,"elapsed":6760,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}},"outputId":"3ac55911-f2d4-4180-a8df-14e08bf75801"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["OpenAI API 키를 입력하세요: ··········\n"]}]},{"cell_type":"markdown","source":["## **2. OpenAI API 호출 함수**\n","- model, message, temperatue, max_tokens를 입력받음"],"metadata":{"id":"I_Z8rtgr0KGV"}},{"cell_type":"code","source":["def create_chat_completion(system_input, user_input, model=\"gpt-3.5-turbo\", temperature=1.15, max_tokens=150):\n","    try:\n","        # 메시지 목록을 자동으로 생성해요\n","        messages = [\n","            {\"role\": \"system\", \"content\": system_input},\n","            {\"role\": \"user\", \"content\": user_input}\n","        ]\n","\n","        response = OpenAI().chat.completions.create(\n","            model=model,\n","            messages=messages,\n","            temperature=temperature,\n","            max_tokens=max_tokens  # 최대 토큰 수를 지정해요\n","        )\n","        # 생성된 응답을 반환해요\n","        return response\n","    except Exception as e:\n","        return f\"Error: {str(e)}\"\n"],"metadata":{"id":"mhT4Uf8-sWj1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메시지 입력\n","system_input = \"넌 AI 전문 강사아. AI, 개발에 관련된 질문에만 친절하고 간략하게 답변해줘\"\n","user_input = \"LLM으로 무엇을 할 수 있는지 설명해줘.\"\n","\n","# API 호출 및 결과 출력\n","responses = create_chat_completion(system_input, user_input)\n","responses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_hic1hmsWhj","outputId":"5b6955a0-aa5e-47d2-d8ba-bca2e13741b1","executionInfo":{"status":"ok","timestamp":1737506776643,"user_tz":-540,"elapsed":2498,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatCompletion(id='chatcmpl-AsJAoZ5gdB178vMMy4IDQry2nuQ9V', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='LLM은 일반적으로 법학 석사학위인 Master of Laws를 나타냅니다. LLM 소지자는 유사한 법학 학위를 가진 학생들에게 더 깊은 법학 지식과 전문성을 제공합니다. LLM 졸업생은 법률 분야에서 다양한 경력을 쌓을 수 있습니다. 이에는 변호사, 법학 교수, 법학 연구원 등이 있습니다. 또한 LLM 소지자', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737506778, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=73, total_tokens=223, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["responses.choices[0].message.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"ZtbfnGbJsWUS","outputId":"571304fb-5d0a-4641-b526-a04b123e50b3","executionInfo":{"status":"ok","timestamp":1737506795316,"user_tz":-540,"elapsed":353,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'LLM은 일반적으로 법학 석사학위인 Master of Laws를 나타냅니다. LLM 소지자는 유사한 법학 학위를 가진 학생들에게 더 깊은 법학 지식과 전문성을 제공합니다. LLM 졸업생은 법률 분야에서 다양한 경력을 쌓을 수 있습니다. 이에는 변호사, 법학 교수, 법학 연구원 등이 있습니다. 또한 LLM 소지자'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# openai api 이미지"],"metadata":{"id":"8drik3vQrnTp"}},{"cell_type":"code","source":["import json, os\n","# from openai import OpenAI\n","import pandas as pd\n","from openai import OpenAI\n","from getpass import getpass\n","\n","# Colab에 API 키를 안전하게 입력받기\n","api_key = getpass(\"OpenAI API 키를 입력하세요: \")\n","\n","# API 키를 환경 변수에 저장\n","os.environ['OPENAI_API_KEY'] = api_key"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acsHliRMrtXU","executionInfo":{"status":"ok","timestamp":1737510305664,"user_tz":-540,"elapsed":8475,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}},"outputId":"bf2becea-df40-483d-e128-17846cb86416"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["OpenAI API 키를 입력하세요: ··········\n"]}]},{"cell_type":"code","source":["import openai\n","\n","API_KEY = os.getenv('OPENAI_API_KEY')\n","client = openai.OpenAI(api_key = API_KEY)\n","\n","my_image_url = 'https://mblogthumb-phinf.pstatic.net/20110105_214/dapapr_1294200472447D2cs9_JPEG/noname08.jpg?type=w420'\n","my_prompt = '이미지가 어떤 내용인지 해석해줘'\n","\n","\n","response = client.chat.completions.create(\n","  model=\"gpt-4o-mini\",\n","  messages=[\n","    {\n","      \"role\": \"user\",\n","      \"content\": [\n","        {\"type\": \"text\", \"text\": my_prompt},\n","        {\n","          \"type\": \"image_url\",\n","          \"image_url\": {\n","            \"url\": my_image_url,\n","          },\n","        },\n","      ],\n","    }\n","  ],\n","  max_tokens=300,\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"JY9VnqQ6rvlb","executionInfo":{"status":"error","timestamp":1737511825171,"user_tz":-540,"elapsed":670,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}},"outputId":"55f23e8a-ac63-47e7-f121-e82f2de00497"},"execution_count":null,"outputs":[{"output_type":"error","ename":"BadRequestError","evalue":"Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-f45f09476fbd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   messages=[\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    857\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             body=maybe_transform(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         return self._process_response(\n","\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","client = OpenAI()\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": \"이미지가 어떤 내용인지 해석해줘\",\n","                },\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n","                    },\n","                },\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\n","                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n","                    },\n","                },\n","            ],\n","        }\n","    ],\n","    max_tokens=300,\n",")\n","print(response.choices[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRyldI0OvAGs","executionInfo":{"status":"ok","timestamp":1737511538544,"user_tz":-540,"elapsed":12261,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}},"outputId":"a75198f9-3ef1-41d2-90bc-a30d11ae1da8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='이 이미지는 평온한 자연 경관을 보여주고 있습니다. 넓은 초원에 나무들이 어우러져 있으며, 가운데에는 나무로 만들어진 보도가 있는 모습입니다. 하늘은 푸르고 구름이 드리워져 있어 맑고 화창한 날씨인 것처럼 보입니다. 초원은 푸르른 풀로 가득 차 있으며, 전체적으로 휴식과 평화로운 분위기를 느낄 수 있는 풍경입니다. 이는 자연 속에서의 산책이나 탐험을 떠올리게 합니다.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"]}]},{"cell_type":"code","source":["import base64\n","from openai import OpenAI\n","\n","client = OpenAI()\n","\n","# Function to encode the image\n","def encode_image(image_path):\n","    with open(image_path, \"rb\") as image_file:\n","        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n","\n","\n","# Path to your image\n","image_path_0000 = \"/content/tennis_detection_0000.jpg\"\n","image_path_0001 = \"/content/tennis_detection_0001.jpg\"\n","\n","# Getting the base64 string\n","base64_image_0000 = encode_image(image_path_0000)\n","base64_image_0001 = encode_image(image_path_0001)\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\n","                    \"type\": \"text\",\n","                    \"text\": \"이미지가 어떤 흐름으로 흘러가는지 해석해줘\",\n","                },\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image_0000}\"},\n","                },\n","                {\n","                    \"type\": \"image_url\",\n","                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image_0001}\"},\n","                },\n","            ],\n","        }\n","    ],\n",")\n","\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wyEKB0Dxs9l","executionInfo":{"status":"ok","timestamp":1737545266251,"user_tz":-540,"elapsed":9462,"user":{"displayName":"yeonwoo sung","userId":"14441304181571713210"}},"outputId":"bc37daea-d245-4e6a-e88b-30cadc17a073"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["주어진 이미지는 테니스 경기가 진행되는 모습을 보여줍니다. 첫 번째 이미지와 두 번째 이미지에서 나타나는 흐름을 분석해보면 다음과 같습니다.\n","\n","1. **첫 번째 이미지**: \n","   - 노박 조코비치와 케이 니시코리가 경기를 하고 있습니다.\n","   - 조코비치가 준비 자세를 취하고 있으며, 네트 중앙에는 공이 위치해 있습니다.\n","   - 점수판에는 조코비치의 점수(1점)가 표시되어 있고, 니시코리의 점수는 0점입니다.\n","   - 배경에는 관중들과 경기의 분위기가 포착되어 있습니다.\n","\n","2. **두 번째 이미지**:\n","   - 조코비치가 샷을 준비하고 있는 모습이 보입니다.\n","   - 흰 선으로 표시된 코트의 구역들이 강조되어 있어서, 공이 어느 방향으로 날아갈지를 예측할 수 있는 시각적 신호가 제공됩니다.\n","   - 이전과 동일하게 점수판은 유지되고, 니시코리가 반대편에서 조코비치를 바라보며 대기하고 있습니다.\n","\n","이 두 이미지를 통해, 테니스 경기에서 뚜렷한 주도권을 가진 조코비치가 공을 타격하기 위해 준비하는 과정을 볼 수 있습니다. 경기의 흐름은 조코비치의 샷에 의해 계속 진행될 것으로 예상됩니다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RUI87K8IxwSQ"},"execution_count":null,"outputs":[]}]}